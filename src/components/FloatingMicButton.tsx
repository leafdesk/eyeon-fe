'use client'

import { useState, useRef, useEffect, RefObject } from 'react'
import { Mic, MicOff, ChevronUp, ChevronDown } from 'lucide-react'

// Web Speech API íƒ€ì… ì •ì˜
interface SpeechRecognitionEvent extends Event {
  resultIndex: number
  results: SpeechRecognitionResultList
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  start(): void
  stop(): void
  onresult: ((event: SpeechRecognitionEvent) => void) | null
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null
  onend: (() => void) | null
}

interface SpeechRecognitionStatic {
  new (): SpeechRecognition
}

declare global {
  interface Window {
    SpeechRecognition?: SpeechRecognitionStatic
    webkitSpeechRecognition?: SpeechRecognitionStatic
  }
}

interface InputField {
  ref: RefObject<HTMLInputElement | HTMLTextAreaElement | null>
  setValue: (value: string | ((prev: string) => string)) => void
  label?: string
}

interface FloatingMicButtonProps {
  inputFields: InputField[]
  lang?: string
  onStatusChange?: (isListening: boolean, currentFieldIndex: number) => void
  onFieldChange?: (newFieldIndex: number) => void
  currentFieldIndex?: number
  className?: string
}

export default function FloatingMicButton({
  inputFields,
  lang = 'ko-KR',
  onStatusChange,
  onFieldChange,
  currentFieldIndex: externalCurrentFieldIndex = 0,
  className = '',
}: FloatingMicButtonProps) {
  // ì…ë ¥ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ì¡°ê¸° return
  if (inputFields.length === 0) {
    return null
  }

  const [isListening, setIsListening] = useState(false)
  const [currentFieldIndex, setCurrentFieldIndex] = useState(
    externalCurrentFieldIndex,
  )
  const recognitionRef = useRef<SpeechRecognition | null>(null)

  // ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ì€ currentFieldIndexì™€ ë™ê¸°í™”
  useEffect(() => {
    setCurrentFieldIndex(externalCurrentFieldIndex)
  }, [externalCurrentFieldIndex])

  useEffect(() => {
    // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
    if (
      typeof window !== 'undefined' &&
      (window.webkitSpeechRecognition || window.SpeechRecognition)
    ) {
      // SpeechRecognition ì´ˆê¸°í™”
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition
      if (SpeechRecognition) {
        recognitionRef.current = new SpeechRecognition()

        if (recognitionRef.current) {
          recognitionRef.current.continuous = true
          recognitionRef.current.interimResults = true
          recognitionRef.current.lang = lang

          recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {
            let finalTranscript = ''

            for (let i = event.resultIndex; i < event.results.length; i++) {
              const transcript = event.results[i][0].transcript
              if (event.results[i].isFinal) {
                finalTranscript += transcript
              }
            }

            if (finalTranscript && inputFields[currentFieldIndex]) {
              const currentField = inputFields[currentFieldIndex]
              console.log(`ğŸ¤ [FloatingMicButton] STT ì…ë ¥ ê°ì§€:`)
              console.log(`   - í˜„ì¬ ì¸ë±ìŠ¤: ${currentFieldIndex}`)
              console.log(`   - í˜„ì¬ í•„ë“œ ë¼ë²¨: ${currentField.label}`)
              console.log(`   - ì¸ì‹ëœ í…ìŠ¤íŠ¸: "${finalTranscript}"`)
              console.log(`   - ì…ë ¥ í•„ë“œë“¤ ì´ ê°œìˆ˜: ${inputFields.length}`)

              currentField.setValue((prev) => {
                const newValue = prev + finalTranscript
                console.log(
                  `ğŸ“ [FloatingMicButton] setValue ì‹¤í–‰: "${prev}" â†’ "${newValue}"`,
                )
                return newValue
              })
            }
          }

          recognitionRef.current.onerror = (
            event: SpeechRecognitionErrorEvent,
          ) => {
            // no-speechëŠ” ì •ìƒì ì¸ ë™ì‘ì´ë¯€ë¡œ ì—ëŸ¬ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
            if (event.error === 'no-speech') {
              console.log(
                'ğŸ”‡ [FloatingMicButton] ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ìë™ ì¢…ë£Œë¨ (ì •ìƒ)',
              )
            } else {
              console.error(
                'âŒ [FloatingMicButton] ìŒì„± ì¸ì‹ ì˜¤ë¥˜:',
                event.error,
              )
            }
            setIsListening(false)
            onStatusChange?.(false, currentFieldIndex)
          }

          recognitionRef.current.onend = () => {
            setIsListening(false)
            onStatusChange?.(false, currentFieldIndex)
          }
        }
      }
    } else {
      console.log(
        'FloatingMicButton: ë¸Œë¼ìš°ì €ê°€ ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. UIëŠ” ë Œë”ë§ë˜ì§€ë§Œ ìŒì„± ê¸°ëŠ¥ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.',
      )
    }
  }, [lang, currentFieldIndex, inputFields, onStatusChange])

  const focusCurrentField = () => {
    const currentField = inputFields[currentFieldIndex]
    if (currentField?.ref.current) {
      currentField.ref.current.focus()
      // ì»¤ì„œë¥¼ í…ìŠ¤íŠ¸ ëìœ¼ë¡œ ì´ë™
      const element = currentField.ref.current
      const length = element.value.length
      element.setSelectionRange(length, length)
    }
  }

  const moveToNextField = () => {
    if (currentFieldIndex < inputFields.length - 1) {
      const nextIndex = currentFieldIndex + 1
      console.log(
        `\n\n\nğŸ”„ [FloatingMicButton] ë‹¤ìŒ í•„ë“œë¡œ ì´ë™: ${currentFieldIndex} â†’ ${nextIndex}`,
      )
      setCurrentFieldIndex(nextIndex)
      onFieldChange?.(nextIndex)
      setTimeout(() => {
        const nextField = inputFields[nextIndex]
        if (nextField?.ref.current) {
          nextField.ref.current.focus()
          const element = nextField.ref.current
          const length = element.value.length
          element.setSelectionRange(length, length)
          console.log(
            `âœ… [FloatingMicButton] ë‹¤ìŒ í•„ë“œ í¬ì»¤ìŠ¤ ì™„ë£Œ: index ${nextIndex}, label: ${nextField.label}`,
          )
        }
      }, 100)
    }
  }

  const moveToPrevField = () => {
    if (currentFieldIndex > 0) {
      const prevIndex = currentFieldIndex - 1
      console.log(
        `ğŸ”„ [FloatingMicButton] ì´ì „ í•„ë“œë¡œ ì´ë™: ${currentFieldIndex} â†’ ${prevIndex}`,
      )
      setCurrentFieldIndex(prevIndex)
      onFieldChange?.(prevIndex)
      setTimeout(() => {
        const prevField = inputFields[prevIndex]
        if (prevField?.ref.current) {
          prevField.ref.current.focus()
          const element = prevField.ref.current
          const length = element.value.length
          element.setSelectionRange(length, length)
          console.log(
            `âœ… [FloatingMicButton] ì´ì „ í•„ë“œ í¬ì»¤ìŠ¤ ì™„ë£Œ: index ${prevIndex}, label: ${prevField.label}`,
          )
        }
      }, 100)
    }
  }

  const toggleListening = () => {
    if (!recognitionRef.current) {
      console.log(
        'FloatingMicButton: ìŒì„± ì¸ì‹ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì§€ì›ì„ í™•ì¸í•´ì£¼ì„¸ìš”.',
      )
      return
    }

    if (isListening) {
      console.log(
        `ğŸ”´ [FloatingMicButton] ìŒì„± ì¸ì‹ ì¤‘ì§€ (í˜„ì¬ í•„ë“œ: ${currentFieldIndex})`,
      )
      recognitionRef.current.stop()
      setIsListening(false)
      onStatusChange?.(false, currentFieldIndex)
    } else {
      console.log(
        `ğŸŸ¢ [FloatingMicButton] ìŒì„± ì¸ì‹ ì‹œì‘ (í˜„ì¬ í•„ë“œ: ${currentFieldIndex})`,
      )
      recognitionRef.current.start()
      setIsListening(true)
      focusCurrentField()
      onStatusChange?.(true, currentFieldIndex)
    }
  }

  return (
    <div
      className={`fixed bottom-6 right-6 flex flex-col items-end gap-2 ${className}`}
    >
      {/* í•„ë“œ ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼ë“¤ (ìŒì„± ì¸ì‹ ì¤‘ì¼ ë•Œë§Œ í‘œì‹œ) */}
      {isListening && inputFields.length > 1 && (
        <div className="flex flex-col gap-2 bg-[#0e1525] rounded-lg shadow-lg p-3 border border-[#FFD700]/20">
          <button
            onClick={moveToPrevField}
            disabled={currentFieldIndex === 0}
            className="w-12 h-12 bg-[#FFD700]/10 hover:bg-[#FFD700]/20 disabled:opacity-30 disabled:cursor-not-allowed rounded-lg transition-colors flex items-center justify-center border border-[#FFD700]/30"
            aria-label="ì´ì „ í•„ë“œë¡œ ì´ë™"
          >
            <ChevronUp className="w-8 h-8 text-[#FFD700]" />
          </button>

          {/* í˜„ì¬ í•„ë“œ í‘œì‹œ (ìˆ«ìë¡œ í‘œì‹œ) */}
          <div className="flex items-center justify-center py-2">
            <div className="text-sm font-medium text-[#FFD700]">
              {currentFieldIndex + 1}/{inputFields.length}
            </div>
          </div>

          <button
            onClick={moveToNextField}
            disabled={currentFieldIndex === inputFields.length - 1}
            className="w-12 h-12 bg-[#FFD700]/10 hover:bg-[#FFD700]/20 disabled:opacity-30 disabled:cursor-not-allowed rounded-lg transition-colors flex items-center justify-center border border-[#FFD700]/30"
            aria-label="ë‹¤ìŒ í•„ë“œë¡œ ì´ë™"
          >
            <ChevronDown className="w-8 h-8 text-[#FFD700]" />
          </button>
        </div>
      )}

      {/* ë©”ì¸ ë§ˆì´í¬ ë²„íŠ¼ */}
      <button
        onClick={toggleListening}
        className={`w-16 h-16 rounded-full shadow-lg transition-all duration-200 flex items-center justify-center ${
          isListening
            ? 'bg-red-500 hover:bg-red-600 animate-pulse'
            : 'bg-[#FFD700] hover:bg-[#FFD700]/90'
        }`}
        aria-label={isListening ? 'ìŒì„± ì¸ì‹ ì¤‘ì§€' : 'ìŒì„± ì¸ì‹ ì‹œì‘'}
      >
        {isListening ? (
          <MicOff className="w-6 h-6 text-white" />
        ) : (
          <Mic className="w-6 h-6 text-[#0F1626]" />
        )}
      </button>
    </div>
  )
}
